Warning: This module should only be used with the A100 GPU nodes.  If you are using the K80 or Titan-X GPUs please use an older cuda version.
WARNING: If you use conda to create environments, your home directory may fill up. Please see our documentation at 
 https://www.wiki.ed.ac.uk/display/ResearchServices/Anaconda for advice.
Traceback (most recent call last):
  File "test.py", line 26, in <module>
    check_cuda()
  File "test.py", line 15, in check_cuda
    x = torch.rand(10, 10, device=device)  # move tensor
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

